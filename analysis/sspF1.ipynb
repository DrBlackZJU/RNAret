{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from retnet import RetNet,RetNetConfig\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def constraint(seq):\n",
    "    L = len(seq)\n",
    "    matrix = np.zeros((L, L), dtype=int)\n",
    "\n",
    "    for i in range(4, L):\n",
    "        for j in range(i-4):\n",
    "            base_i = seq[i]\n",
    "            base_j = seq[j]\n",
    "            if  ((base_i == 'A' and base_j == 'U') or (base_i == 'U' and base_j == 'A') or\n",
    "                (base_i == 'C' and base_j == 'G') or (base_i == 'G' and base_j == 'C') or\n",
    "                (base_i == 'G' and base_j == 'U') or (base_i == 'U' and base_j == 'G') or\n",
    "                base_i == 'N' or base_j == 'N'):\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "class outer_concat(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(outer_concat, self).__init__()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        seq_len = x1.shape[1]\n",
    "        x1 = x1.unsqueeze(-2).expand(-1, -1, seq_len, -1)\n",
    "        x2 = x2.unsqueeze(-3).expand(-1, seq_len, -1, -1)\n",
    "        x = torch.concat((x1,x2),dim=-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet2DBlock(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, kernel_size=3, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=embed_dim, out_channels=embed_dim, kernel_size=1, bias=bias),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=embed_dim, out_channels=embed_dim, kernel_size=kernel_size, bias=bias, padding=\"same\"),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=embed_dim, out_channels=embed_dim, kernel_size=1, bias=bias),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.conv_net(x)\n",
    "        x = x + residual\n",
    "\n",
    "        return x\n",
    "    \n",
    "class ResNet2D(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_blocks, kernel_size=3, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = torch.nn.ModuleList(\n",
    "            [\n",
    "                ResNet2DBlock(embed_dim, kernel_size, bias=bias) for _ in range(num_blocks)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x    \n",
    "    \n",
    "class ResNet2D_classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet2D_classifier, self).__init__()\n",
    "        self.outer_concat = outer_concat()\n",
    "        self.linear_in = torch.nn.Linear(768,128)\n",
    "        self.resnet = ResNet2D(128, 16, 3, bias=True)\n",
    "        self.conv_out = torch.nn.Conv2d(128, 1, kernel_size=3, padding=\"same\")\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.outer_concat(x, x)\n",
    "        x = self.linear_in(x)\n",
    "        x = x.permute(0,3,1,2)\n",
    "        x = self.resnet(x)\n",
    "\n",
    "        x = self.conv_out(x)\n",
    "        x = x.squeeze(1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class rnaret_ssp_model(torch.torch.nn.Module): \n",
    "    def __init__(self, args):\n",
    "        super(rnaret_ssp_model, self).__init__()\n",
    "        self.ret = RetNet(args)\n",
    "        self.classifier = ResNet2D_classifier()\n",
    "\n",
    "    def forward(self, x):      \n",
    "        _,aux  = self.ret(x)\n",
    "        x = aux['inner_states'][-1]\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "class post_process(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(post_process, self).__init__()\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = torch.sigmoid(x)\n",
    "        x = x * mask\n",
    "        \n",
    "        sec_struct = torch.where(x > 0.5, torch.ones_like(x), torch.zeros_like(x))\n",
    "        x = x * sec_struct\n",
    "        \n",
    "        B, L, _ = x.shape\n",
    "        \n",
    "        for b in range(B):\n",
    "            tmp = x[b].clone()\n",
    "            row_ind, col_ind = linear_sum_assignment(-tmp.detach().cpu().numpy())\n",
    "            binary_matrix = torch.zeros_like(tmp)\n",
    "            for r, c in zip(row_ind, col_ind):\n",
    "                binary_matrix[r, c] = 1\n",
    "                \n",
    "            sec_struct[b] = binary_matrix\n",
    "\n",
    "        sec_struct = sec_struct * mask\n",
    "        \n",
    "        sec_struct = sec_struct + sec_struct.transpose(1,2)\n",
    "        \n",
    "        for b in range(B):\n",
    "            for i in range(L):\n",
    "                if torch.sum(sec_struct[b, i, :]) > 1:\n",
    "                    max_idx = torch.argmax(sec_struct[b, i, :])\n",
    "                    sec_struct[b, i, :] = 0\n",
    "                    sec_struct[b, i, max_idx] = 1\n",
    "\n",
    "                if torch.sum(sec_struct[b, :, i]) > 1:\n",
    "                    max_idx = torch.argmax(sec_struct[b, :, i])\n",
    "                    sec_struct[b, :, i] = 0\n",
    "                    sec_struct[b, max_idx, i] = 1\n",
    "        \n",
    "        return sec_struct\n",
    "        \n",
    "    \n",
    "class seq_tokenizer():\n",
    "    def __init__(self, k=5, max_len=512):\n",
    "        self.k = k\n",
    "        self.max_len = max_len\n",
    "    def tokenize(self, seq):\n",
    "        kmer_list = np.array([''.join(p) for p in itertools.product('ATCG', repeat=self.k)])\n",
    "        kmer_to_index = {kmer: idx + 6 for idx, kmer in enumerate(kmer_list)}\n",
    "        seq = seq.upper()\n",
    "        seq = seq.replace('U','T')\n",
    "        seq_len = len(seq)\n",
    "        \n",
    "        tokens = np.zeros(self.max_len, dtype=np.int16)\n",
    "        \n",
    "        kmers = np.array([seq[i:i+self.k] for i in range(seq_len - self.k + 1)])\n",
    "        \n",
    "        indices = np.array([kmer_to_index.get(kmer, 2) for kmer in kmers])\n",
    "        \n",
    "        tokens[self.k//2:self.k//2+len(indices)] = indices[:]\n",
    "        \n",
    "        tokens[:self.k//2] = 1\n",
    "        tokens[self.k//2+len(indices):self.k//2+len(indices)+(self.k-1)//2] = 1\n",
    "        return tokens\n",
    "    \n",
    "def parse_bpseq_file(file, max_len=512):\n",
    "    matrix = np.zeros((max_len, max_len), dtype=np.int8)\n",
    "    seq = ''\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        if file.endswith(\".bpseq\"):\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                idx, nt, pair = parts\n",
    "                seq = seq + nt\n",
    "\n",
    "    return seq\n",
    "\n",
    "class seq_tokenizer():\n",
    "    def __init__(self, k=5, max_len=512):\n",
    "        self.k = k\n",
    "        self.max_len = max_len\n",
    "    def tokenize(self, seq):\n",
    "        kmer_list = np.array([''.join(p) for p in itertools.product('ATCG', repeat=self.k)])\n",
    "        kmer_to_index = {kmer: idx + 6 for idx, kmer in enumerate(kmer_list)}\n",
    "        seq = seq.upper()\n",
    "        seq = seq.replace('U','T')\n",
    "        seq_len = len(seq)\n",
    "        \n",
    "        tokens = np.zeros(seq_len, dtype=np.int16)\n",
    "        \n",
    "        kmers = np.array([seq[i:i+self.k] for i in range(seq_len - self.k + 1)])\n",
    "        \n",
    "        indices = np.array([kmer_to_index.get(kmer, 2) for kmer in kmers])\n",
    "        \n",
    "        tokens[self.k//2:self.k//2+len(indices)] = indices[:]\n",
    "        \n",
    "        tokens[:self.k//2] = 1\n",
    "        tokens[self.k//2+len(indices):self.k//2+len(indices)+(self.k-1)//2] = 1\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class ssp_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir,max_len, k=5):\n",
    "        self.data_dir = data_dir\n",
    "        self.matrices = []\n",
    "        self.seqs = []\n",
    "        self.constraint = []\n",
    "        self.tokenizer = seq_tokenizer(k=k,max_len=max_len)\n",
    "        self.labels = []\n",
    "\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for filename in files:\n",
    "                if filename.endswith(\".bpseq\"):\n",
    "                    file_path = os.path.join(root, filename)\n",
    "                    matrix, seq_len, seq = parse_bpseq_file(file_path, max_len=max_len)\n",
    "                    if matrix is not None and seq_len <= max_len:\n",
    "                        con_matrix = constraint(seq, max_len)\n",
    "                        seq = self.tokenizer.tokenize(seq)\n",
    "                        self.matrices.append(matrix)\n",
    "                        self.seqs.append(seq)\n",
    "                        self.constraint.append(con_matrix)\n",
    "                        self.labels.append(filename.split('_')[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.seqs[idx], self.matrices[idx], self.constraint[idx],self.labels[idx]\n",
    "    \n",
    "def compute_metrics(target, prediction):\n",
    "    positive_mask = target == 1\n",
    "    negative_mask = target == 0\n",
    "    pred_positive_mask = prediction > 0\n",
    "    \n",
    "    tp = torch.sum(torch.logical_and(positive_mask, pred_positive_mask)).item()\n",
    "    fp = torch.sum(torch.logical_and(negative_mask, pred_positive_mask)).item()\n",
    "    fn = torch.sum(torch.logical_and(positive_mask, ~pred_positive_mask)).item()\n",
    "    tn = torch.sum(torch.logical_and(negative_mask, ~pred_positive_mask)).item()\n",
    "    \n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "\n",
    "k = 1\n",
    "model_config = RetNetConfig(vocab_size=4**k+6,retnet_embed_dim=384, retnet_value_embed_dim=512,\n",
    "                            retnet_ffn_embed_dim=512,retnet_layers=8,retnet_retention_heads=4,\n",
    "                            dropout=0.2,activation_dropout=0.2)\n",
    "    \n",
    "model = rnaret_ssp_model(model_config)\n",
    "model.load_state_dict(torch.load(\"../model/ssp/RNAStrAlign_1mer.pth\",weights_only=True))\n",
    "\n",
    "post_processor = post_process()\n",
    "model = model.to(device)\n",
    "    \n",
    "\n",
    "test_datasets = []\n",
    "for data_dir in \"../data/archiveII\":\n",
    "    dataset = ssp_dataset(data_dir, max_len=600, k=k)\n",
    "    test_datasets.append(dataset)\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_datasets)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.amp.autocast(device_type='cuda'):\n",
    "    with torch.no_grad():\n",
    "        total_precision = []\n",
    "        total_recall = []\n",
    "        total_f1 = []\n",
    "        total_type = []\n",
    "        lengths = []\n",
    "        for x, y, mask,type in test_dataloader:\n",
    "            x = x.to(torch.long).to(device) \n",
    "            length = x.size(1)\n",
    "            y = y.to(torch.float32).to(device)\n",
    "            mask = mask.to(torch.int).to(device)\n",
    "            prob = model(x)\n",
    "            pred = post_processor(prob, mask)\n",
    "            precision, recall, f1 = compute_metrics(y, pred)\n",
    "            total_precision.append(precision)\n",
    "            total_recall.append(recall)\n",
    "            total_f1.append(f1)\n",
    "            total_type.extend(type)\n",
    "            lengths.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Type': total_type, 'F1 Score': total_f1}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "order = ['5s', '16s', '23s', 'tRNA', 'tmRNA', 'grp1', 'srp', 'RNaseP']\n",
    "\n",
    "df['Type'] = pd.Categorical(df['Type'], categories=order, ordered=True)\n",
    "df = df.sort_values('Type')\n",
    "\n",
    "mean_f1_scores = df.groupby('Type')['F1 Score'].mean().reindex(order)\n",
    "\n",
    "custom_colors = sns.color_palette(\"Set3\", n_colors=len(df['Type'].unique()))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "violin_plot = sns.violinplot(\n",
    "    x='Type', \n",
    "    y='F1 Score', \n",
    "    data=df, \n",
    "    palette=custom_colors,\n",
    "    order=order,  \n",
    "    inner='box',  \n",
    "    linewidth=1,  \n",
    "    linecolor='grey',\n",
    "    width=0.6\n",
    ")\n",
    "\n",
    "plt.scatter(df['Type'], df['F1 Score'], s=3, color='black', zorder=5) \n",
    "\n",
    "y_offset = -0.1 \n",
    "for i, (type_name, mean_score) in enumerate(mean_f1_scores.items()):\n",
    "    plt.text(i, 1 - y_offset, f'{mean_score:.3f}', horizontalalignment='center', fontsize=10, verticalalignment='bottom')\n",
    "\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xlabel('RNA Type')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig(\"sspF1.pdf\", format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.regplot(x=lengths, y=total_f1, scatter_kws={'alpha':0.5, 's':4}, line_kws={'color': '#E29135','lw': 1.2})\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"sspLen.pdf\", format='pdf',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
